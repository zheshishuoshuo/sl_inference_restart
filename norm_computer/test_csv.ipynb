{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ba2514a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rows=1005000, uniques=(100, 100, 100, 1), expected=1000000, diff=5000\n",
      "duplicate combos: 5000 (show top 10)\n",
      "      mu_DM  sigma_DM   beta_DM  xi_DM  size\n",
      "0      12.0  0.100000  1.181818      0     2\n",
      "3330   12.0  0.265657  2.919192      0     2\n",
      "3337   12.0  0.269697  1.767677      0     2\n",
      "3336   12.0  0.269697  1.585859      0     2\n",
      "3335   12.0  0.269697  1.565657      0     2\n",
      "3334   12.0  0.269697  1.383838      0     2\n",
      "3333   12.0  0.269697  1.323232      0     2\n",
      "3332   12.0  0.269697  1.262626      0     2\n",
      "3331   12.0  0.269697  1.181818      0     2\n",
      "3329   12.0  0.265657  2.737374      0     2\n",
      "\n",
      "by mu (重复条数汇总):\n",
      "mu_DM\n",
      "12.0    10000\n",
      "Name: size, dtype: int64\n",
      "\n",
      "by sigma (重复条数汇总):\n",
      "sigma_DM\n",
      "0.213131    200\n",
      "0.285859    200\n",
      "0.196970    200\n",
      "0.201010    200\n",
      "0.205051    200\n",
      "0.350505    200\n",
      "0.326263    200\n",
      "0.217172    200\n",
      "0.221212    200\n",
      "0.225253    200\n",
      "Name: size, dtype: int64\n",
      "\n",
      "by beta (重复条数汇总):\n",
      "beta_DM\n",
      "1.767677    152\n",
      "1.383838    152\n",
      "1.323232    152\n",
      "1.262626    150\n",
      "1.929293    150\n",
      "1.585859    150\n",
      "2.919192    150\n",
      "1.808081    150\n",
      "1.828283    150\n",
      "1.848485    150\n",
      "Name: size, dtype: int64\n",
      "\n",
      "by xi (重复条数汇总):\n",
      "xi_DM\n",
      "0    10000\n",
      "Name: size, dtype: int64\n",
      "\n",
      "missing combos: 0 (show top 10)\n",
      "Empty DataFrame\n",
      "Columns: [mu_DM, sigma_DM, beta_DM, xi_DM]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "csv = \"../tables/A_phys_table_4D.csv\"  # 改成你的路径\n",
    "PREC = 6                     # 生成时用的 prec\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "\n",
    "# 仅保留关键信息，并对网格坐标做一致的量化\n",
    "keys = [\"mu_DM\",\"sigma_DM\",\"beta_DM\",\"xi_DM\"]\n",
    "df = df[keys + [\"A_phys\"]].copy()\n",
    "for c in keys:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").round(PREC)\n",
    "\n",
    "# 1) 基本规模检查\n",
    "N = len(df)\n",
    "mu_u, sg_u, bt_u, xi_u = (np.sort(df[c].unique()) for c in keys)\n",
    "expected = len(mu_u) * len(sg_u) * len(bt_u) * len(xi_u)\n",
    "print(f\"#rows={N}, uniques=({len(mu_u)}, {len(sg_u)}, {len(bt_u)}, {len(xi_u)}), expected={expected}, diff={N-expected}\")\n",
    "\n",
    "# 2) 查重复：同一键出现 >1 次的行\n",
    "dups = df.duplicated(subset=keys, keep=False)\n",
    "dup_df = (df[dups]\n",
    "          .groupby(keys, as_index=False)\n",
    "          .size()\n",
    "          .sort_values(\"size\", ascending=False))\n",
    "print(f\"duplicate combos: {len(dup_df)} (show top 10)\")\n",
    "print(dup_df.head(10))\n",
    "\n",
    "# 2.1 汇总在哪些切片重复（帮助你快速定位是哪个块被写重了）\n",
    "if len(dup_df):\n",
    "    print(\"\\nby mu (重复条数汇总):\")\n",
    "    print(dup_df.groupby(\"mu_DM\")[\"size\"].sum().sort_values(ascending=False).head(10))\n",
    "    print(\"\\nby sigma (重复条数汇总):\")\n",
    "    print(dup_df.groupby(\"sigma_DM\")[\"size\"].sum().sort_values(ascending=False).head(10))\n",
    "    print(\"\\nby beta (重复条数汇总):\")\n",
    "    print(dup_df.groupby(\"beta_DM\")[\"size\"].sum().sort_values(ascending=False).head(10))\n",
    "    print(\"\\nby xi (重复条数汇总):\")\n",
    "    print(dup_df.groupby(\"xi_DM\")[\"size\"].sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "# 3) 查缺失：构造满笛卡尔积，与现有键做反连接\n",
    "grid = pd.MultiIndex.from_product(\n",
    "    [mu_u, sg_u, bt_u, xi_u],\n",
    "    names=keys\n",
    ").to_frame(index=False)\n",
    "\n",
    "merged = grid.merge(df[keys], on=keys, how=\"left\", indicator=True)\n",
    "missing = merged[merged[\"_merge\"] == \"left_only\"][keys]\n",
    "print(f\"\\nmissing combos: {len(missing)} (show top 10)\")\n",
    "print(missing.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "811263f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old: 1005000 new: 1000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "keys = [\"mu_DM\",\"sigma_DM\",\"beta_DM\",\"xi_DM\"]\n",
    "df = pd.read_csv(\"../tables/A_phys_table_4D.csv\")\n",
    "df_clean = df.drop_duplicates(subset=keys, keep=\"first\")\n",
    "print(\"old:\", len(df), \"new:\", len(df_clean))  # 应从 1,005,000 变 1,000,000\n",
    "df_clean.to_csv(\"../tables/A_phys_table_4D_new.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77bc2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
